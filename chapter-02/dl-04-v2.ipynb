{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"qo1aOv\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v3.2.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"qo1aOv\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"qo1aOv\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from lets_plot import *\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "LetsPlot.setup_html()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dataset(\n",
    "    train_transformers=transforms.ToTensor(), test_transformers=transforms.ToTensor()\n",
    ") -> tuple[Dataset, Dataset]:\n",
    "    mnist_train_dataset = datasets.MNIST(\n",
    "        root=\"./data\", train=True, download=True, transform=train_transformers\n",
    "    )\n",
    "    mnist_test_dataset = datasets.MNIST(\n",
    "        root=\"./data\", train=False, download=True, transform=test_transformers\n",
    "    )\n",
    "    return mnist_train_dataset, mnist_test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dataloaders(\n",
    "    batch_size: int, train_dataset: Dataset, test_dataset: Dataset\n",
    ") -> tuple[DataLoader, DataLoader]:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset, mnist_test_dataset = get_mnist_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataloder, mnist_test_dataloder = get_mnist_dataloaders(\n",
    "    64, mnist_train_dataset, mnist_test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_image(idx: int, dataset: Dataset):\n",
    "    image, label = dataset[idx]\n",
    "    image_reshaped = image.reshape(28, 28)\n",
    "\n",
    "    plt.imshow(image_reshaped, cmap=\"gray\")\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_dataset_image(4, mnist_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing with kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blurring_image(image: torch.Tensor, kernel_size: int = 3) -> torch.Tensor:\n",
    "    kernel = torch.ones(kernel_size, kernel_size) / kernel_size**2\n",
    "    return F.conv2d(image.unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "\n",
    "def edging_image(image: torch.Tensor):\n",
    "    kernel = torch.tensor([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=torch.float)\n",
    "    return F.conv2d(image.unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "\n",
    "def finding_horizontal_lines(image: torch.Tensor):\n",
    "    kernel = torch.tensor([[1, 1, 1], [0, 0, 0], [-1, -1, -1]], dtype=torch.float)\n",
    "    return F.conv2d(image.unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "\n",
    "def finding_vertical_lines(image: torch.Tensor):\n",
    "    kernel = torch.tensor([[1, 0, -1], [1, 0, -1], [1, 0, -1]], dtype=torch.float)\n",
    "    return F.conv2d(image.unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _ = mnist_train_dataset[90]\n",
    "\n",
    "new_image = blurring_image(image)\n",
    "\n",
    "plt.imshow(image.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(new_image.reshape(26, 26), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _ = mnist_train_dataset[90]\n",
    "\n",
    "new_image = edging_image(image)\n",
    "\n",
    "plt.imshow(image.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(new_image.reshape(26, 26), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _ = mnist_train_dataset[90]\n",
    "\n",
    "new_image = finding_horizontal_lines(image)\n",
    "\n",
    "plt.imshow(image.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(new_image.reshape(26, 26), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _ = mnist_train_dataset[90]\n",
    "\n",
    "new_image = finding_vertical_lines(image)\n",
    "\n",
    "plt.imshow(image.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(new_image.reshape(26, 26), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 64  # batch size\n",
    "D = 28 * 28  # image dimensionality\n",
    "C = 1  # number of channels\n",
    "classes = 10\n",
    "filters = 16\n",
    "kernel_size = 3\n",
    "\n",
    "fc_model = nn.Sequential(\n",
    "    nn.Flatten(),  # (B, C, W, H) -> (B, C * W * H) = (B, D)\n",
    "    nn.Linear(D, 256),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(256, classes),\n",
    ")\n",
    "\n",
    "model_conv = nn.Sequential(\n",
    "    nn.Conv2d(C, filters, kernel_size, padding=kernel_size // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(filters * D, classes),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate\n",
    "\n",
    "Esse é apenas um código boilerplate para o treinamento de uma rede neural. O mesmo foi retirado do livro Inside Deep Learning e é uma mão na roda para não precisarmos ficar reescrevendo o loop de treino.\n",
    "\n",
    "Juntamente com o loop, temos algumas funcionalidades como salvar o modelo, métricas, loss, mover os tensores pro device correto, entre outras coisas...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveTo(obj, device):\n",
    "    \"\"\"\n",
    "    obj: the python object to move to a device, or to move its contents to a device\n",
    "    device: the compute device to move objects to\n",
    "    \"\"\"\n",
    "    if hasattr(obj, \"to\"):\n",
    "        return obj.to(device)\n",
    "    elif isinstance(obj, list):\n",
    "        return [moveTo(x, device) for x in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(moveTo(list(obj), device))\n",
    "    elif isinstance(obj, set):\n",
    "        return set(moveTo(list(obj), device))\n",
    "    elif isinstance(obj, dict):\n",
    "        to_ret = dict()\n",
    "        for key, value in obj.items():\n",
    "            to_ret[moveTo(key, device)] = moveTo(value, device)\n",
    "        return to_ret\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "def run_epoch(\n",
    "    model,\n",
    "    optimizer,\n",
    "    data_loader,\n",
    "    loss_func,\n",
    "    device,\n",
    "    results,\n",
    "    score_funcs,\n",
    "    prefix=\"\",\n",
    "    desc=None,\n",
    "):\n",
    "    running_loss = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    start = time.time()\n",
    "    for inputs, labels in tqdm(data_loader, desc=desc, leave=False):\n",
    "        # Move the batch to the device we are using.\n",
    "        inputs = moveTo(inputs, device)\n",
    "        labels = moveTo(labels, device)\n",
    "\n",
    "        y_hat = model(inputs)  # this just computed f_Θ(x(i))\n",
    "        # Compute loss.\n",
    "        loss = loss_func(y_hat, labels)\n",
    "\n",
    "        if model.training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Now we are just grabbing some information we would like to have\n",
    "        running_loss.append(loss.item())\n",
    "\n",
    "        if len(score_funcs) > 0 and isinstance(labels, torch.Tensor):\n",
    "            # moving labels & predictions back to CPU for computing / storing predictions\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            y_hat = y_hat.detach().cpu().numpy()\n",
    "            # add to predictions so far\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(y_hat.tolist())\n",
    "    # end training epoch\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    if (\n",
    "        len(y_pred.shape) == 2 and y_pred.shape[1] > 1\n",
    "    ):  # We have a classification problem, convert to labels\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    # Else, we assume we are working on a regression problem\n",
    "\n",
    "    results[prefix + \" loss\"].append(np.mean(running_loss))\n",
    "    for name, score_func in score_funcs.items():\n",
    "        try:\n",
    "            results[prefix + \" \" + name].append(score_func(y_true, y_pred))\n",
    "        except:\n",
    "            results[prefix + \" \" + name].append(float(\"NaN\"))\n",
    "    return end - start  # time spent on epoch\n",
    "\n",
    "\n",
    "def train_simple_network(\n",
    "    model,\n",
    "    loss_func,\n",
    "    train_loader,\n",
    "    test_loader=None,\n",
    "    score_funcs=None,\n",
    "    epochs=50,\n",
    "    device=\"cpu\",\n",
    "    checkpoint_file=None,\n",
    "    lr=0.001,\n",
    "):\n",
    "    to_track = [\"epoch\", \"total time\", \"train loss\"]\n",
    "\n",
    "    if test_loader is not None:\n",
    "        to_track.append(\"test loss\")\n",
    "    for eval_score in score_funcs:\n",
    "        to_track.append(\"train \" + eval_score)\n",
    "        if test_loader is not None:\n",
    "            to_track.append(\"test \" + eval_score)\n",
    "\n",
    "    total_train_time = 0  # How long have we spent in the training loop?\n",
    "    results = {}\n",
    "    # Initialize every item with an empty list\n",
    "    for item in to_track:\n",
    "        results[item] = []\n",
    "\n",
    "    # SGD is Stochastic Gradient Decent.\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "    # Place the model on the correct compute resource (CPU or GPU)\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        model = model.train()  # Put our model in training mode\n",
    "\n",
    "        total_train_time += run_epoch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            train_loader,\n",
    "            loss_func,\n",
    "            device,\n",
    "            results,\n",
    "            score_funcs,\n",
    "            prefix=\"train\",\n",
    "            desc=\"Training\",\n",
    "        )\n",
    "\n",
    "        results[\"total time\"].append(total_train_time)\n",
    "        results[\"epoch\"].append(epoch)\n",
    "\n",
    "        if test_loader is not None:\n",
    "            model = model.eval()\n",
    "            with torch.no_grad():\n",
    "                run_epoch(\n",
    "                    model,\n",
    "                    optimizer,\n",
    "                    test_loader,\n",
    "                    loss_func,\n",
    "                    device,\n",
    "                    results,\n",
    "                    score_funcs,\n",
    "                    prefix=\"test\",\n",
    "                    desc=\"Testing\",\n",
    "                )\n",
    "\n",
    "    if checkpoint_file is not None:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"results\": results,\n",
    "            },\n",
    "            checkpoint_file,\n",
    "        )\n",
    "\n",
    "    return pl.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "cnn_results = train_simple_network(\n",
    "    model_conv,\n",
    "    loss_func,\n",
    "    mnist_train_dataloder,\n",
    "    mnist_test_dataloder,\n",
    "    score_funcs={\"accuracy\": accuracy_score},\n",
    "    device=\"cuda\",\n",
    "    epochs=2,\n",
    "    checkpoint_file=\"./model/cnn_checkpoint.pth\",\n",
    ")\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "fc_results = train_simple_network(\n",
    "    fc_model,\n",
    "    loss_func,\n",
    "    mnist_train_dataloder,\n",
    "    mnist_test_dataloder,\n",
    "    score_funcs={\"accuracy\": accuracy_score},\n",
    "    device=\"cuda\",\n",
    "    epochs=2,\n",
    "    checkpoint_file=\"./model/cnn_checkpoint.pth\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pl.concat(\n",
    "    [\n",
    "        fc_results.with_columns(pl.lit(\"Fully Connected\").alias(\"nn_type\")),\n",
    "        cnn_results.with_columns(pl.lit(\"CNN\").alias(\"nn_type\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "(\n",
    "    ggplot(results, aes(x=\"epoch\", y=\"test accuracy\", group=\"nn_type\", color=\"nn_type\"))\n",
    "    + geom_line()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando movimentação do objeto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 10\n",
    "img, correct_class = mnist_train_dataset[img_idx]\n",
    "img = img.reshape(28, 28)\n",
    "img_lr = np.roll(np.roll(img, 4, axis=1), 1, axis=0)\n",
    "img_ul = np.roll(np.roll(img, -4, axis=1), -1, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 3)\n",
    "axarr[0].imshow(img, cmap=\"gray\")\n",
    "axarr[1].imshow(img_lr, cmap=\"gray\")\n",
    "axarr[2].imshow(img_ul, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando o modelo treinado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_conv.cpu().eval()  # passing to cpu to be simpler\n",
    "\n",
    "\n",
    "def pred(model, img):\n",
    "    with torch.no_grad():\n",
    "        w, h = img.shape\n",
    "\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            img = torch.tensor(img)\n",
    "\n",
    "        # We need add some dimensions to the image so that it is in the correct shape\n",
    "        x = img.reshape(1, -1, w, h)\n",
    "        logits = model(x)\n",
    "\n",
    "        # We need to apply softmax to get the probabilities\n",
    "        y_hat = F.softmax(logits, dim=1)\n",
    "\n",
    "    return y_hat.numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lr_pred = pred(model, img_lr)\n",
    "img_pred = pred(model, img)\n",
    "img_ul_pred = pred(model, img_ul)\n",
    "\n",
    "print(\n",
    "    f\"Predicted class for original image: {np.argmax(img_pred)} / Probability: {img_pred[np.argmax(img_pred)]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class for left-right image: {np.argmax(img_lr_pred)} / Probability: {img_lr_pred[np.argmax(img_lr_pred)]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class for up-left image: {np.argmax(img_ul_pred)} / Probability: {img_ul_pred[np.argmax(img_ul_pred)]}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_pool = nn.Sequential(\n",
    "    nn.Conv2d(C, filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(filters, filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(filters, filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(filters, 2 * filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(2 * filters, 2 * filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(2 * filters, 2 * filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2 * filters * D // (4**2), classes),\n",
    ")\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "cnn_results_with_pool = train_simple_network(\n",
    "    model_cnn_pool,\n",
    "    loss_func,\n",
    "    mnist_train_dataloder,\n",
    "    mnist_test_dataloder,\n",
    "    score_funcs={\"accuracy\": accuracy_score},\n",
    "    device=\"cuda\",\n",
    "    epochs=1,\n",
    "    checkpoint_file=\"./model/cnn_pooling_checkpoint.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool = model_cnn_pool.cpu().eval()  # passing to cpu to be simpler\n",
    "\n",
    "img_pred = pred(model_pool, img)\n",
    "img_lr_pred = pred(model_pool, img_lr)\n",
    "img_ul_pred = pred(model_pool, img_ul)\n",
    "\n",
    "print(\n",
    "    f\"Predicted class for original image: {np.argmax(img_pred)} / Probability: {img_pred[np.argmax(img_pred)]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class for left-right image: {np.argmax(img_lr_pred)} / Probability: {img_lr_pred[np.argmax(img_lr_pred)]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class for up-left image: {np.argmax(img_ul_pred)} / Probability: {img_ul_pred[np.argmax(img_ul_pred)]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing with pooling and without\n",
    "results = pl.concat(\n",
    "    [\n",
    "        cnn_results.with_columns(pl.lit(\"Without Pooling\").alias(\"pooling\")),\n",
    "        cnn_results_with_pool.with_columns(pl.lit(\"With Pooling\").alias(\"pooling\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "(\n",
    "    ggplot(results, aes(x=\"epoch\", y=\"test accuracy\", group=\"pooling\", color=\"pooling\"))\n",
    "    + geom_line()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transforms = {\n",
    "    \"Rotation\": transforms.RandomAffine(degrees=45),\n",
    "    \"Translation\": transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    \"Shear\": transforms.RandomAffine(0, shear=45),\n",
    "    \"RandomCrop\": transforms.RandomCrop((20, 20)),\n",
    "    \"Horizontal Flip\": transforms.RandomHorizontalFlip(p=1.0),\n",
    "    \"Vertical Flip\": transforms.RandomVerticalFlip(p=1.0),\n",
    "    \"Color Jitter\": transforms.ColorJitter(\n",
    "        brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5\n",
    "    ),\n",
    "    \"Perspective\": transforms.RandomPerspective(p=1.0),\n",
    "}\n",
    "\n",
    "pil_img = transforms.ToPILImage()(img)\n",
    "\n",
    "f, axarr = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "for i, (name, transform) in enumerate(sample_transforms.items()):\n",
    "    pil_img_transformed = transform(pil_img)\n",
    "    axarr[i // 4, i % 4].imshow(pil_img_transformed, cmap=\"gray\")\n",
    "    axarr[i // 4, i % 4].set_title(name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "test_transform = transforms.ToTensor()\n",
    "\n",
    "mnist_dataset_train_v2, mnist_dataset_test_v2 = get_mnist_dataset(\n",
    "    train_transformers=train_transform, test_transformers=test_transform\n",
    ")\n",
    "mnist_train_dataloder_v2, mnist_test_dataloader_v2 = get_mnist_dataloaders(\n",
    "    B, mnist_dataset_train_v2, mnist_dataset_test_v2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "model_cnn_pool_data_aug = nn.Sequential(\n",
    "    nn.Conv2d(C, filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(filters, filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(filters, filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(filters, 2 * filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(2 * filters, 2 * filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.Conv2d(2 * filters, 2 * filters, 3, padding=3 // 2),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2 * filters * D // (4**2), classes),\n",
    ")\n",
    "\n",
    "cnn_results_with_pool_w_data_aug = train_simple_network(\n",
    "    model_cnn_pool_data_aug,\n",
    "    loss_func,\n",
    "    mnist_test_dataloader_v2,\n",
    "    mnist_test_dataloader_v2,\n",
    "    score_funcs={\"accuracy\": accuracy_score},\n",
    "    device=\"cuda\",\n",
    "    epochs=1,\n",
    "    checkpoint_file=\"./model/cnn_pooling_checkpoint_w_data_aug.pth\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing with pooling and without\n",
    "results = pl.concat(\n",
    "    [\n",
    "        cnn_results_with_pool.with_columns(pl.lit(\"With Pooling\").alias(\"pooling\")),\n",
    "        cnn_results_with_pool_w_data_aug.with_columns(\n",
    "            pl.lit(\"Without Pooling\").alias(\"pooling\")\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "(\n",
    "    ggplot(results, aes(x=\"epoch\", y=\"test accuracy\", group=\"pooling\", color=\"pooling\"))\n",
    "    + geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v3 = model_cnn_pool_data_aug.cpu().eval()  # passing to cpu to be simpler\n",
    "\n",
    "img_pred = pred(model_v3, img)\n",
    "img_lr_pred = pred(model_v3, img_lr)\n",
    "img_ul_pred = pred(model_v3, img_ul)\n",
    "\n",
    "print(\n",
    "    f\"Predicted class for original image: {np.argmax(img_pred)} / Probability: {img_pred[np.argmax(img_pred)]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class for left-right image: {np.argmax(img_lr_pred)} / Probability: {img_lr_pred[np.argmax(img_lr_pred)]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class for up-left image: {np.argmax(img_ul_pred)} / Probability: {img_ul_pred[np.argmax(img_ul_pred)]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-blog-posts-TOWhFNmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
